{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "**Warning :**   \n",
    "The data set used in the present tutorial to train embeddings contains only 50 lines (emails). This is not sufficient to obtain meaningful results.  \n",
    "\n",
    "Feel free to replace the data set with your own data (at least 10000 documents is recommended) and you should observe significant improvement in the results. The quality of an embedding can be assessed, for exemple, by using the most_similar method on a word and making sure that the words obtained are coherent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:30:28.153281Z",
     "start_time": "2019-10-09T12:30:26.855904Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_emails_clean = pd.read_csv('./data/emails_preprocessed.csv', encoding='utf-8', sep=';')\n",
    "# Artificially increase df size by duplication\n",
    "df_emails_clean = pd.concat([df_emails_clean] * 100, ignore_index=True) \n",
    "df_emails_clean = df_emails_clean[['clean_body']]\n",
    "df_emails_clean = df_emails_clean.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:30:28.170329Z",
     "start_time": "2019-10-09T12:30:28.157333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'je vous informe que la nouvelle immatriculation est enfin faite. je vous prie de trouver donc la carte grise ainsi que la nouvelle immatriculation. je vous demanderai de faire les changements necessaires concernant lassurance.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails_clean.clean_body[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Embedding class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings are abstract representations of words in a lower dimensional vector space. One of the advantages of word embeddings is thus to save computational cost. \n",
    "\n",
    "There are several methods to train word embeddings, Melusine provides high level functions to train word embeddings using different methods and benchmark the resuls. The types of word embeddings available in the **Embedding** class are:\n",
    "- `lsa_docterm` : Apply a Singular Value Decomposition (SVD) on the DocTerm matrix\n",
    "- `lsa_tfidf` : Apply a Singular Value Decomposition (SVD) on the TfIdf matrix\n",
    "- `word2vec_sg` : Train a Word2Vec model using the Skip-Gram method (Warning : time consuming!)\n",
    "- `word2vec_cbow` : Train a Word2Vec model using the Continuous Bag-Of-Words method.\n",
    "\n",
    "The Melusine **Embedding** class can be used to benchmark word embeddings training methods in a straightforward manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:30:30.887160Z",
     "start_time": "2019-10-09T12:30:28.172746Z"
    }
   },
   "outputs": [],
   "source": [
    "from melusine.nlp_tools.embedding import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:30:31.139606Z",
     "start_time": "2019-10-09T12:30:30.889232Z"
    }
   },
   "outputs": [],
   "source": [
    "min_count = 2\n",
    "n_dimension = 50\n",
    "\n",
    "embedding_lsa_docterm = Embedding(input_column='clean_body',\n",
    "                                  vector_size=n_dimension,\n",
    "                                  min_count=min_count,\n",
    "                                  method = 'lsa_docterm')\n",
    "\n",
    "embedding_lsa_tfidf = Embedding(input_column='clean_body',\n",
    "                                  vector_size=n_dimension,\n",
    "                                  min_count=min_count,\n",
    "                                  method = 'lsa_tfidf')\n",
    "\n",
    "embedding_word2vec_sg = Embedding(input_column='clean_body',\n",
    "                                  vector_size=n_dimension,\n",
    "                                  min_count=min_count,\n",
    "                                  method = 'word2vec_sg')\n",
    "\n",
    "\n",
    "embedding_word2vec_cbow = Embedding(input_column='clean_body',\n",
    "                                  vector_size=n_dimension,\n",
    "                                  min_count=min_count,\n",
    "                                  method = 'word2vec_cbow')\n",
    "\n",
    "embeddings_list = [embedding_lsa_docterm, embedding_lsa_tfidf, embedding_word2vec_sg, embedding_word2vec_cbow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:30:37.104122Z",
     "start_time": "2019-10-09T12:30:31.141484Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n"
     ]
    }
   ],
   "source": [
    "for embedding in embeddings_list:\n",
    "    embedding.train(df_emails_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:03:31.952112Z",
     "start_time": "2019-10-09T12:03:31.949098Z"
    }
   },
   "source": [
    "## Changing the train parameters\n",
    "\n",
    "There are parameters that can be tuned to optimize the training of word embeddings. The most widely used parameters can be specified directly when the **Embedding** class object is instanciated :  \n",
    "* `size` : number of dimension of the embedding\n",
    "* `min_count` : minimum number of occurence of a word to be included in the embedding vocabulary\n",
    "\n",
    "Other training parameters can be specified in the **Embedding** attribute train_params which is a dictionnary of parameters. Keep in mind that some training parameters are specific to a given embedding training method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:30:37.163559Z",
     "start_time": "2019-10-09T12:30:37.106115Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_word2vec_cbow = Embedding(input_column='clean_body',\n",
    "                                  vector_size=100,\n",
    "                                  min_count=3,\n",
    "                                  method = 'word2vec_cbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:30:37.187124Z",
     "start_time": "2019-10-09T12:30:37.166295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train parameters for a Word2Vec CBOW embedding:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vector_size': 100,\n",
       " 'alpha': 0.025,\n",
       " 'min_count': 3,\n",
       " 'max_vocab_size': None,\n",
       " 'sample': 0.001,\n",
       " 'seed': 42,\n",
       " 'workers': 40,\n",
       " 'min_alpha': 0.0001,\n",
       " 'negative': 5,\n",
       " 'hs': 0,\n",
       " 'ns_exponent': 0.75,\n",
       " 'cbow_mean': 1,\n",
       " 'epochs': 15,\n",
       " 'null_word': 0,\n",
       " 'trim_rule': None,\n",
       " 'sorted_vocab': 1,\n",
       " 'batch_words': 10000,\n",
       " 'compute_loss': False,\n",
       " 'callbacks': (),\n",
       " 'max_final_vocab': None,\n",
       " 'sg': 0,\n",
       " 'window': 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train parameters for a Word2Vec CBOW embedding:\")\n",
    "embedding_word2vec_cbow.train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:30:38.623780Z",
     "start_time": "2019-10-09T12:30:37.191803Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Start training for embedding\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n",
      "21/05 10:54 - melusine.nlp_tools.embedding - INFO - Done.\n"
     ]
    }
   ],
   "source": [
    "# Change a training parameter before training the embedding\n",
    "embedding_word2vec_cbow.train_params[\"window\"] = 3\n",
    "embedding_word2vec_cbow.train(df_emails_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gensim Word2VecKeyedVectors object\n",
    "\n",
    "Regardless of the selected method (lsa_docterm, word2vec, etc), the trained embedding is converted to a Gensim **Word2VecKeyedVectors** object and stored in the embedding attribute of the **Embedding** class (`Embedding.embedding`). This very convenient as it enables the use of all the **Word2VecKeyedVectors** functions. Examples of such functions are:\n",
    "* `similarity` : Compute the cosine similarity between two words \n",
    "* `most_similar` : Compute the words most similar to the input word \n",
    "* See more methods in the Gensim documentation\n",
    "\n",
    "Warning : The Word2VecKeyedVectors object is originally developped for Word2Vec word embeddings, therefore, some functions, such as the \"accuracy\" function, are specific to Word2Vec embeddings and should not be used if the embedding was trained using a DocTerm_LSA method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:30:38.643237Z",
     "start_time": "2019-10-09T12:30:38.629971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'telephone' and 'numero'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88935524"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'telephone' and 'numero'\")\n",
    "embedding.embedding.wv.similarity(\"telephone\", \"numero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:30:38.659042Z",
     "start_time": "2019-10-09T12:30:38.647771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'telephone' and 'manifestation'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.073899984"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'telephone' and 'manifestation'\")\n",
    "embedding.embedding.wv.similarity(\"telephone\", \"manifestation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word \"telephone\" is closer to the word \"numero\" than the word \"manifestation\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:30:38.670287Z",
     "start_time": "2019-10-09T12:30:38.661823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('telephone', 0.8893551826477051),\n",
       " ('fils', 0.8416222929954529),\n",
       " ('joins', 0.8325093984603882),\n",
       " ('tel', 0.8192885518074036),\n",
       " ('entretien', 0.7805293798446655),\n",
       " ('jour', 0.7715598344802856),\n",
       " ('flag_phone_', 0.7486917972564697),\n",
       " ('telephonique', 0.7449696660041809),\n",
       " ('suite', 0.6457016468048096),\n",
       " ('scan', 0.6169107556343079)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.embedding.wv.most_similar(\"numero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the present exemple \"telephone\" appears as the word most similar to \"numero\" which is an intuitive outcome. However, due to the very limited amount of training data, some words are not very relevant (Ex: \"joins\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing2",
   "language": "python",
   "name": "testing2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
